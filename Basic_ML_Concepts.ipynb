{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c705a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.SPLITTING A DATASET INTO TRAINING AND TESTING SETS USING PYTHON'S SKLEARN LIBRARY\n",
    "\n",
    "  \n",
    "    \n",
    "##We can split a dataset into training and testing sets using the train_test_split function from scikit-learn. \n",
    "#Here's a brief code snippet demonstrating how to do it:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Assuming X is features and y is target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#-X_train and y_train will contain the training data\n",
    "#-X_test and y_test will contain the testing data\n",
    "\n",
    "In this code snippet:\n",
    "\n",
    "#-X represents the Features of the dataset.\n",
    "#-y represents the Target variable of the dataset.\n",
    "#-test_size specifies the proportion of the dataset to include in the testing split. Here, it's set to 0.2, meaning 20% of the data will be used for testing, and 80% will be used for training.\n",
    "\n",
    "#-random_state sets the seed for random number generation. It ensures that the data split is reproducible across multiple runs. It's optional but recommended for reproducibility.\n",
    "\n",
    "#-After running this code, X_train and y_train will contain the training data, while X_test and y_test will contain the testing data.We can then use these splits to train and evaluate our machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d176afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec48ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 1.0\n",
      "Intercept: 1.0\n"
     ]
    }
   ],
   "source": [
    "#2.A PYTHON FUNCTION TO PERFORM SIMPLE LINEAR REGRESSION FOR A GIVEN DATASET,\n",
    "#USING ONLY BASIC MATHEMATICAL OPERATIONS.\n",
    "\n",
    "\n",
    "#Python function to perform simple linear regression using basic mathematical operations:\n",
    "\n",
    "def simple_linear_regression(X, y):\n",
    "    n = len(X)\n",
    "    \n",
    "    # Calculate the mean of X and y\n",
    "    mean_X = sum(X) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the slope (m) and intercept (b)\n",
    "    numerator = sum((X[i] - mean_X) * (y[i] - mean_y) for i in range(n))\n",
    "    denominator = sum((X[i] - mean_X) ** 2 for i in range(n))\n",
    "    \n",
    "    m = numerator / denominator\n",
    "    b = mean_y - m * mean_X\n",
    "    \n",
    "    return m, b\n",
    "\n",
    "# Example:\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [2, 3, 4, 5, 6]\n",
    "\n",
    "m, b = simple_linear_regression(X, y)\n",
    "print(\"Slope:\", m)\n",
    "print(\"Intercept:\", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4139557",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22374f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.5\n"
     ]
    }
   ],
   "source": [
    "#3.IMPLEMENTING A PYTHON FUNCTION TO CALCULATE THE MEAN ABSOLUTE ERROR(MAE)FOR A REGRESSION MODEL,\n",
    "#WITHOUT USING   ANY EXTERNAL LIBRARIES.\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    \n",
    "    # Calculate the absolute errors\n",
    "    abs_errors = [abs(y_true[i] - y_pred[i]) for i in range(n)]\n",
    "    \n",
    "    # Calculate the mean absolute error\n",
    "    mae = sum(abs_errors) / n\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Example usage:\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c963f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73ab018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammadsalman/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#4.CREATING A PYTHON CODE TO BUILD A LOGISTIC REGRESSION MODEL USING SKLEARN.\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Iris dataset \n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cac85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87ea6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "#5.A PYTHON FUNCTION TO CLASSIFY A NEW DATA POINT USING K-NEAREST NEIGHBORS(KNN)ALGORITHM\n",
    "#WITHOUT USING SKLEARN.\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))\n",
    "\n",
    "def knn_predict(X_train, y_train, X_test, k):\n",
    "    \"\"\"\n",
    "    Predict the class label for a new data point using KNN algorithm.\n",
    "    \"\"\"\n",
    "    # Initialize list to store predicted labels\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each data point in the test set\n",
    "    for test_point in X_test:\n",
    "        # Calculate distances to all points in the training set\n",
    "        distances = [euclidean_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get indices of k nearest neighbors\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        \n",
    "        # Get labels of k nearest neighbors\n",
    "        nearest_labels = [y_train[i] for i in nearest_indices]\n",
    "        \n",
    "        # Predict the most common label among k nearest neighbors\n",
    "        predicted_label = max(set(nearest_labels), key=nearest_labels.count)\n",
    "        \n",
    "        # Append predicted label to the list\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Example:\n",
    "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y_train = np.array([0, 0, 1, 1])\n",
    "X_test = np.array([[1.5, 2.5], [3.5, 4.5]])\n",
    "k = 3\n",
    "\n",
    "y_pred = knn_predict(X_train, y_train, X_test, k)\n",
    "print(\"Predicted Labels:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a8e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5257a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6.DEVELOPING A PYTHON CODE TO TRAIN A DECISION TREE CLASSIFIER USING SKLEARN WITH A STRAIGHTFORWORD EXAMPLE.\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841ad79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
